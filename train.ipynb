{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import utils as vutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import utils as vutils\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dir_list, transform=None):\n",
    "        self.dir_list = dir_list\n",
    "        self.transform = transform\n",
    "\n",
    "        self.datas, self.labels = self.load_data(dir_list)\n",
    "\n",
    "    def load_data(self, class_list):\n",
    "        datas = []\n",
    "        labels = []\n",
    "        for name in class_list:\n",
    "            data = np.load(f'dataset\\\\{name}\\\\data.npy', allow_pickle=True)\n",
    "            \n",
    "            if name == 'normal':\n",
    "                label = np.ones(len(data))\n",
    "            else:\n",
    "                label = np.zeros(len(data))\n",
    "            if len(datas) == 0:\n",
    "                datas = data\n",
    "                labels = label\n",
    "            else:\n",
    "\n",
    "                datas = np.concatenate([datas, data],axis=0)\n",
    "                labels = np.concatenate([labels, label])\n",
    "        datas = np.transpose(datas, (0, 2, 1))  \n",
    "        \n",
    "        max_list = np.amax(datas, axis=2)\n",
    "        max = np.amax(max_list, axis=0)\n",
    "        print(max)\n",
    "        max_x = max[0]\n",
    "        max_y = max[1]\n",
    "        datas[:][0] = datas[:][0]/max_x\n",
    "        datas[:][1] = datas[:][1]/max_y\n",
    "\n",
    "        #print(datas)\n",
    "        \n",
    "        \n",
    "        return datas, labels\n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = self.datas[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        \n",
    "        return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[644.0021    449.46243     0.9781028]\n"
     ]
    }
   ],
   "source": [
    "transforms_ = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "data_list = ['normal', 'bad_leg']\n",
    "mydataset = MyDataset(data_list, transforms_)\n",
    "train_len = int(len(mydataset)*0.8)\n",
    "test_len = len(mydataset) - train_len\n",
    "train_set, val_set = torch.utils.data.random_split(mydataset, [train_len, test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1129"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=75, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc4 = nn.Linear(in_features=64, out_features=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.leaky_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = nn.functional.leaky_relu(x)\n",
    "        output = self.fc4(x)\n",
    "        # output = nn.functional.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device 0 NVIDIA GeForce RTX 2080 with Max-Q Design\n",
      "[644.0021    449.46243     0.9781028]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", torch.cuda.current_device(), torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.002)\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "transforms_ = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "data_list = ['normal', 'bad_leg']\n",
    "mydataset = MyDataset(data_list, transforms_)\n",
    "train_len = int(len(mydataset)*0.8)\n",
    "test_len = len(mydataset) - train_len\n",
    "train_set, test_set = torch.utils.data.random_split(mydataset, [train_len, test_len])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8216050267219543 acc:  0.5185185185185185\n",
      "loss: 0.2955153286457062 acc:  0.8149305555555555\n",
      "loss: 0.11084799468517303 acc:  0.9527777777777778\n",
      "loss: 0.14201174676418304 acc:  0.9707175925925926\n",
      "loss: 0.07996608316898346 acc:  0.9707175925925926\n",
      "loss: 0.15369637310504913 acc:  0.9738425925925925\n",
      "loss: 0.2348400503396988 acc:  0.9371527777777778\n",
      "loss: 0.030021093785762787 acc:  0.9769675925925926\n",
      "loss: 0.236335217952728273 acc:  0.9707175925925926\n",
      "loss: 0.6275307536125183 acc:  0.9582175925925925\n",
      "loss: 0.11422302573919296 acc:  0.9601851851851851\n",
      "loss: 0.0074761416763067245 acc:  0.978125\n",
      "loss: 0.04473799839615822 acc:  0.984375\n",
      "loss: 0.10187452286481857 acc:  0.975\n",
      "loss: 0.019047854468226433 acc:  0.984375\n",
      "loss: 0.01747709885239601 acc:  0.9875\n",
      "loss: 0.030268928036093712 acc:  0.9769675925925926\n",
      "loss: 0.1794118583202362 acc:  0.984375\n",
      "loss: 0.3320147693157196 acc:  0.9769675925925926\n",
      "loss: 0.011837219819426537 acc:  0.9738425925925925\n",
      "loss: 0.003259862307459116 acc:  0.9863425925925926\n",
      "loss: 0.002272272715345025 acc:  0.9875\n",
      "loss: 0.0018602372147142887 acc:  0.978125\n",
      "loss: 0.0170845165848732 acc:  0.978125\n",
      "loss: 0.30204451084136963 acc:  0.984375\n",
      "loss: 0.005195074249058962 acc:  0.971875\n",
      "loss: 0.11495137959718704 acc:  0.9875\n",
      "loss: 0.044367317110300064 acc:  0.98125\n",
      "loss: 0.01835262030363083 acc:  0.9800925925925925\n",
      "loss: 0.10425534099340439 acc:  0.9875\n",
      "loss: 0.004129487555474043 acc:  0.996875\n",
      "loss: 0.0011874862248077989 acc:  0.990625\n",
      "loss: 0.05826232582330704 acc:  0.9769675925925926\n",
      "loss: 0.003972153645008802 acc:  0.990625\n",
      "loss: 0.005637426394969225 acc:  0.99375\n",
      "loss: 0.014577090740203857 acc:  0.9875\n",
      "loss: 0.021790174767374992 acc:  0.99375\n",
      "loss: 0.001228790613822639 acc:  0.9894675925925925\n",
      "loss: 0.0005030040629208088 acc:  0.9832175925925926\n",
      "loss: 0.08804559707641602 acc:  0.9863425925925926\n",
      "loss: 0.002266137395054102 acc:  0.99375\n",
      "loss: 0.021900752559304237 acc:  0.9707175925925926\n",
      "loss: 0.021442435681819916 acc:  0.990625\n",
      "loss: 0.0037688962183892727 acc:  0.99375\n",
      "loss: 0.0032928411383181811 acc:  0.99375\n",
      "loss: 0.001623301999643445 acc:  0.9894675925925925\n",
      "loss: 0.006009414792060852 acc:  0.990625\n",
      "loss: 0.0012419666163623333 acc:  0.9894675925925925\n",
      "loss: 0.003520752303302288 acc:  0.99375\n"
     ]
    }
   ],
   "source": [
    "training_start = time.time()\n",
    "for epoch in range(1,50):\n",
    "    loss_all = 0\n",
    "    net.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        data = batch[0].to(device)\n",
    "        label = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net(data).squeeze()\n",
    "        #output = output.topk(1)[1].squeeze()\n",
    "        \n",
    "        loss = criterion(output, label.long())\n",
    "        loss.backward()\n",
    "        loss_all += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'\\rloss: {loss.item()}',end='')\n",
    "        #print('\\r',loss_all/(i+epoch*len(dataloader)))\n",
    "\n",
    "    acc = 0\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        \n",
    "        net.eval()\n",
    "        data = batch[0].to(device)\n",
    "        label = batch[1].to(device)\n",
    "        \n",
    "        output = net(data).squeeze()\n",
    "        #print(output)\n",
    "        #output = output.topk(1)[1].squeeze()\n",
    "        acc += np.array((torch.argmax(output, dim=1) == label.int()).cpu()).mean()\n",
    "        \n",
    "    print(' acc: ',acc/(i+1))\n",
    "        \n",
    "        \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True], device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([ True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True, False, False,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True], device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True], device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1], device='cuda:0', dtype=torch.int32)\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True], device='cuda:0')\n",
      "0.9613425925925926\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i, batch in enumerate(test_loader):\n",
    "    \n",
    "    net.eval()\n",
    "    data = batch[0].to(device)\n",
    "    label = batch[1].to(device)\n",
    "    \n",
    "    output = net(data).squeeze()\n",
    "    #print(output)\n",
    "    #output = output.topk(1)[1].squeeze()\n",
    "    print(torch.argmax(output, dim=1))\n",
    "    print(label.int())\n",
    "    print((torch.argmax(output, dim=1) == label.int()))\n",
    "    acc += np.array((torch.argmax(output, dim=1) == label.int()).cpu()).mean()\n",
    "    \n",
    "print(acc/(i+1))\n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,1,1])\n",
    "\n",
    "print((a == b).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a7ca93a044b8d93858d22d13a027fb9928cd1d05f68d73722aa8222acbd1a09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
